{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO:\n",
    "- Get at least a reasonable looking change. Maybe start with bad initial conditions.\n",
    "\"\"\"\n",
    "import project_path\n",
    "from model.neural_model import NeuralModel\n",
    "import connectomes\n",
    "import distance\n",
    "import dynamics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "N = 3\n",
    "simul_ts = 1000\n",
    "eval_ts = 500\n",
    "dt = 0.01\n",
    "simul_timepoints = np.arange(0, simul_ts * dt, dt)\n",
    "eval_timepoints = np.arange((simul_ts - eval_ts)*dt, simul_ts * dt, dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Golden dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial run\n",
    "gold_dyn = dynamics.get_jimin_3neuron_dynamics(simul_ts, dt)\n",
    "top_mode_gold_dyn = dynamics.get_top_mode(gold_dyn)\n",
    "preprocessed_gold_dyn = distance.preprocess_pop_dyn(gold_dyn, eval_ts)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 3))\n",
    "ax.plot(simul_timepoints, top_mode_gold_dyn)\n",
    "fig.suptitle(\"Top mode of gold dyn (raw)\")\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 3))\n",
    "ax.plot(eval_timepoints, preprocessed_gold_dyn)\n",
    "fig.suptitle(\"Preprocessed gold dynamics to evaluate against\")\n",
    "_ = _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial unoptimized dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_Gg, init_Gs, is_inhibitory = connectomes.get_random_connectome(N)\n",
    "I_ext = dynamics.get_jimin_3neuron_Iext()\n",
    "initial_dyn = dynamics.run_neural_model(N, init_Gg, init_Gs, is_inhibitory, I_ext, simul_ts, dt)\n",
    "\n",
    "top_mode_initial_dyn = dynamics.get_top_mode(initial_dyn)\n",
    "preprocessed_initial_dyn = distance.preprocess_pop_dyn(initial_dyn, eval_ts)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 3))\n",
    "ax.plot(simul_timepoints, top_mode_initial_dyn)\n",
    "fig.suptitle(\"Top mode of initial dyn (raw)\")\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 3))\n",
    "ax.plot(eval_timepoints, preprocessed_gold_dyn, label=\"gold\", c=\"gold\")\n",
    "ax.plot(eval_timepoints, preprocessed_initial_dyn, label=\"actual\")\n",
    "ax.legend()\n",
    "fig.suptitle(\"Comparison of preprocessed dyns against gold\")\n",
    "\n",
    "error = distance.ts_distance_euclidean(preprocessed_gold_dyn, preprocessed_initial_dyn)\n",
    "print(\"Initial Gg = %s\\n Gs = %s\\n\" % (init_Gg, init_Gs))\n",
    "print(\"Initial error = \" + str(error))\n",
    "_ = _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_obj_fun(N, preprocessed_gold_dyn, eval_ts):\n",
    "  num_called = 0\n",
    "  min_error = 1000000\n",
    "  def obj_fun(compact_vec):\n",
    "    nonlocal num_called\n",
    "    nonlocal min_error\n",
    "    global init_Gg\n",
    "    global init_Gs\n",
    "    num_called += 1\n",
    "    gg_mat, gs_mat = connectomes.compact_to_model_param(compact_vec, N)\n",
    "    pop_dyn = dynamics.run_neural_model(N, gg_mat, gs_mat, is_inhibitory, I_ext, simul_ts, dt)\n",
    "    preprocessed_pop_dyn = distance.preprocess_pop_dyn(pop_dyn, eval_ts)\n",
    "    error = distance.ts_distance_euclidean(preprocessed_gold_dyn, preprocessed_pop_dyn)\n",
    "    min_error = min(min_error, error)\n",
    "    if num_called % 10 == 0:\n",
    "      print(\"Evaluation %s, error = %.2f, min_error = %.2f\" % (num_called, error, min_error))\n",
    "      print(\"Gg = \" + str(gg_mat))\n",
    "      print(\"Gs = \" + str(gs_mat))\n",
    "      print(\"delta Gg = \" + str(init_Gg - gg_mat))\n",
    "      print(\"delta Gs = \" + str(init_Gs - gs_mat))\n",
    "    return error\n",
    "  return obj_fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import basinhopping\n",
    "import time\n",
    "\n",
    "init_cond_compact = connectomes.model_to_compact_param(init_Gg, init_Gs, N)\n",
    "obj_fun = create_obj_fun(N, preprocessed_gold_dyn, eval_ts)\n",
    "bnds = [(0, 10)] * len(init_cond_compact)\n",
    "\n",
    "# See the options from here\n",
    "# https://docs.scipy.org/doc/scipy-0.13.0/reference/generated/scipy.optimize.show_options.html\n",
    "def optimize_with_SLSQP():\n",
    "  return minimize(obj_fun, init_cond_compact, method='SLSQP', bounds=bnds,\n",
    "                  options={'maxiter':2})\n",
    "\n",
    "def optimize_with_L_BFGS_B():\n",
    "  return minimize(obj_fun, init_cond_compact, method='L-BFGS-B', bounds=bnds,\n",
    "                  options={'maxiter':2})\n",
    "\n",
    "def optimize_with_Powell():\n",
    "  options = {}\n",
    "  # options={'maxfev':2}\n",
    "  return minimize(obj_fun, init_cond_compact, method='Powell', bounds=bnds, options=options)\n",
    "\n",
    "def optimize_with_Nelder_mead():\n",
    "  options = {}\n",
    "  # options={'maxfev':2}\n",
    "  return minimize(obj_fun, init_cond_compact, method='Nelder-Mead', bounds=bnds, options=options)\n",
    "\n",
    "\n",
    "def optimize_with_basin_hopping():\n",
    "  minimizer_kwargs = {\"method\":\"Powell\", \"bounds\":bnds}\n",
    "  # You can add niter=k to limit the number of bruteforces\n",
    "  return basinhopping(obj_fun, init_cond_compact, minimizer_kwargs=minimizer_kwargs)\n",
    "  \n",
    "start_time = time.time()\n",
    "res = optimize_with_basin_hopping()\n",
    "print(\"Total optimization time = %.2fs\" % (time.time() - start_time))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_Gg, new_Gs = connectomes.compact_to_model_param(res.x, N)\n",
    "print(\"The optimized Gg and Gs are:\\n%s\\n%s\\n\" % (new_Gg, new_Gs))\n",
    "print(\"Old Gg and Gs are:\\n%s\\n%s\\n\" % (init_Gg, init_Gs))\n",
    "print(\"The difference matrices are:\\n%s\\n%s\\n\" % (new_Gg-init_Gg, new_Gs-init_Gs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare optimized dynamics against golden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the optimized results\n",
    "\n",
    "opt_dyn = dynamics.run_neural_model(N, new_Gg, new_Gs, is_inhibitory, I_ext, simul_ts, dt)\n",
    "\n",
    "top_mode_opt_dyn = dynamics.get_top_mode(opt_dyn)\n",
    "preprocessed_opt_dyn = distance.preprocess_pop_dyn(opt_dyn, eval_ts)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 3))\n",
    "ax.plot(simul_timepoints, top_mode_opt_dyn)\n",
    "fig.suptitle(\"Top mode of opt dyn (raw)\")\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 3))\n",
    "ax.plot(eval_timepoints, preprocessed_gold_dyn, label=\"gold\", c=\"gold\")\n",
    "ax.plot(eval_timepoints, preprocessed_opt_dyn, label=\"actual\")\n",
    "ax.legend()\n",
    "fig.suptitle(\"Comparison of preprocessed dyns against gold, optimized\")\n",
    "\n",
    "error = distance.ts_distance_euclidean(preprocessed_gold_dyn, preprocessed_opt_dyn)\n",
    "print(\"Optimized error = \" + str(error))\n",
    "_ = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
